\documentclass[12pt, a4paper]{article}

% --- Packages ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{url}
\usepackage{array}
\usepackage{float}
\usepackage{enumitem}
\usepackage[margin=1in]{geometry}

% Hyperref (Must be loaded last)
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

\begin{document}
% ----------------------------------------------------------------------
% Title Page
% ----------------------------------------------------------------------
\begin{titlepage}
    \centering
    \vspace*{\fill}

    {\huge \textbf{Acoustic Breathing and Cough Detection for Fatigue Monitoring Using a Laptop Microphone} \par}

    \vspace{2cm}

    {\Large \textbf{Group OLEMFA} \par}
    \vspace{0.5em}
    {\large
    Olena Mikhailova (H7OGWN) \\
    Muhammed Emre Candir (YDY84J) \\
    Faizyab Ali Shah (GUBG3I) \\
    }

    \vspace{1.5em}
    {\small \emph{Course: Biomedical Signal Processing} \par}

    % --- Added GitHub Link Here ---
    \vspace{0.5em}
    {\small Project Repository: \url{https://github.com/faizyabShah/bsp_project} \par}
    % ------------------------------

    \vspace{2cm}
    {\small \today}

    \vspace*{\fill}
\end{titlepage}

% ----------------------------------------------------------------------
% Abstract
% ----------------------------------------------------------------------
\newpage
\begin{abstract}
\noindent
This project investigates whether non-contact acoustic measurements, recorded using a standard laptop microphone, can be used to monitor fatigue-related changes in breathing. We developed a complete signal-processing pipeline that includes envelope extraction, breathing rate estimation, and cough detection. Two distinct machine learning approaches were developed and analyzed: a Feature-Driven Classification system and a foundational Signal Processing system. The Feature-Driven system used a 38-feature vector (combining temporal rhythm, spectral texture, and physical effort features) with an Extra Trees Classifier, achieving an overall multi-class accuracy of 82.5\%. The system proved that Temporal rhythm (BPM/Duty Cycle) is the primary biomarker for acoustic fatigue monitoring. Complementarily, the foundational Signal Processing system successfully implemented a Peak-Based Rate Detection method, achieving 100\% accuracy in the binary classification of Normal vs. Fatigue states using a simple BPM threshold with BRV (Breathing rate variability) used as a tie breaker in close scenarios. The results demonstrate that acoustic data, even from consumer-grade hardware, accurately reflects underlying physiological stress responses.
\end{abstract}

\newpage
\tableofcontents


% ----------------------------------------------------------------------
% 1. Introduction
% ----------------------------------------------------------------------
\newpage
\section{Introduction}

\subsection{Project Overview and Objectives}
Fatigue monitoring is a crucial element in safety-sensitive domains. However, most conventional approaches use intrusive sensors or rely on subjective self-reporting, which can be inconsistent and inaccurate. The project in question suggests an acoustics-based, non-contact solution \cite{larson2011spirosmart}. The goal of this research is to create a three-class acoustic classification system that can differentiate between physiological states using just a typical laptop microphone. The system has been developed for the specific purpose of automatically detecting and classifying raw audio data into the following categories:


\begin{itemize}
    \item Normal Breathing (resting state),
    \item Fatigue Breathing (post-exercise state),
    \item Cough Events.
\end{itemize}

The primary objective is to implement a robust Python-based pipeline for the multi-class detection of these respiratory audio events. As a secondary objective, the present study aims to statistically quantify the acoustic and temporal differences between states. This approach involves the analysis of variations in breathing rate, amplitude, and spectral content, with the objective of identifying reliable biomarkers of fatigue. Furthermore, the entire workflow—from acquisition to feature extraction—is guaranteed to be reproducible and open-source.


\subsection{Research Hypotheses}
To guide the signal processing strategy and feature selection, we formulate three hypotheses regarding the acoustic characteristics of respiratory sounds:

\begin{description}
    \item[H1 (Fatigue Markers):] Fatigue breathing will exhibit statistically significant increases in breathing rate, amplitude, and temporal irregularity compared to normal resting breathing.
    \item[H2 (Cough Differentiation):] Cough sounds possess distinct short-time energy profiles and spectral entropy characteristics, allowing them to be reliably segmented from background breathing noise \cite{swarna2020cough}.
    \item[H3 (Classification Feasibility):] A combination of temporal envelope features and spectral ratios will provide sufficient discriminative power for accurate multi-class classification using non-contact audio.
\end{description}

% ----------------------------------------------------------------------
% 2. Data Collection and Dataset Description
% ----------------------------------------------------------------------
\newpage
\section{Data Collection and Dataset Description}

To support analysis, we collected a controlled dataset consisting of 24 recordings from 8 participants (Emre, Olena, Narmeen, Sneha, Paula, Yernur, Peyman, Sofia). Each participant contributed three recordings corresponding to the target classes: normal breathing, fatigued breathing, and coughing.

Recordings were acquired using standard microphones in quiet indoor environments. The device was positioned approximately 5--10 cm from the participant’s mouth to maintain consistent recording quality while remaining fully non-contact.

Each participant followed a defined protocol:
\begin{enumerate}
    \item \textbf{Normal Breathing:} A 60-second recording captured at rest, producing slow and smooth respiratory cycles.
    \item \textbf{Fatigue Breathing:} Participants performed 2 minutes of physical exercise (stair climbing or squats) and immediately recorded 60 seconds of post-exertion breathing.
    \item \textbf{Cough Recording:} Participants recorded 60 seconds during which they produced deliberate coughs approximately every 5 seconds.
\end{enumerate}

All audio files were manually reviewed to ensure correct labeling. Each recording was stored along with metadata such as the start time, end time, and label for supervised training.

% ======================================================================
% 3. Preprocessing and Envelope Extraction
% ======================================================================
\newpage
\section{Audio Preprocessing and Envelope Extraction}

To transition from raw audio to interpretable respiratory biomarkers, a unified preprocessing pipeline was implemented. This stage aims to mitigate environmental noise, standardize amplitude levels across heterogeneous recording devices, and isolate the low-frequency respiratory component. All audio data was ingested at the native sampling rate using \texttt{librosa} \cite{mcfee2015librosa} before entering the multi-stage processing block.

\subsection{General Preprocessing Pipeline}
Raw audio files were initially sliced strictly according to manual start/end timestamps. Early trials attempting to filter short segments ($< 0.1$ s) resulted in significant data loss (dropping valid short coughs). Therefore, the final pipeline adopted a "No-Filter" approach, preserving all 422 segments to ensure the integrity of transient events like coughs.

\subsection{Respiratory Envelope Extraction}
The core of the analysis relies on the generation of a smooth, time-domain breathing envelope. We define the envelope extraction process as a sequential pipeline designed to demodulate the amplitude of the breathing sounds.

The envelope $E(t)$ is derived from the raw signal $x(t)$ via the Hilbert Transform\cite{liu2013respiratory}:
\begin{equation}
    E(t) = |x(t) + i\mathcal{H}(x(t))|
\end{equation}
where $\mathcal{H}(\cdot)$ denotes the Hilbert operator implemented via \texttt{SciPy} \cite{virtanen2020scipy}. The following steps were applied primarily to support the extraction of Temporal Features (e.g., BPM, IBI):

\begin{description}
    \item[1. Normalization:] Signals were normalized to eliminate subject-dependent loudness differences and microphone gain variations.
    
    \item[2. Savitzky–Golay Smoothing:] To attenuate high-frequency noise while preserving the shape of respiratory peaks, we applied a Savitzky–Golay filter.
    
    \item[3. Low-Pass Filtering:] A cut-off frequency of \textbf{0.7 Hz} was selected. This effectively isolates the respiratory band (corresponding to $\approx$ 42 breaths per minute) and removes heart sounds and muscle artifacts \cite{charlton2018breathing}.
    
    \item[4. Z-Score Normalization:] The signal was normalized to zero mean and unit variance to allow for adaptive thresholding across participants.
    
    \item[5. Downsampling:] The final envelope was downsampled to \textbf{100 Hz} to create a lightweight signal suitable for analysis.
\end{description}

\subsection{Frame-Based Feature Engineering}

To successfully classify the three physiological states (Normal, Fatigue, and Cough), it was necessary to extract a rich, high-dimensional feature set that captures both the subtle texture of continuous breathing and the impulsive nature of cough events. These features were computed using a short-time framing approach applied to the segmented audio before aggressive low-pass filtering, preserving the high-frequency content critical for spectral analysis. The final feature vector aggregated 38 metrics, categorized as follows:

\subsubsection{Spectral and Texture Features}
These features analyze the frequency domain to describe the characteristic "sound" or timbre of the respiratory signal.

\begin{itemize}
    \item \textbf{Mel-Frequency Cepstral Coefficients (MFCCs):} A set of $13$ coefficients and their corresponding standard deviations were extracted to form a $26$-dimensional vector. MFCCs are widely used to represent the spectral envelope of biological sounds \cite{palaniappan2013biological}.
    \item \textbf{Spectral Centroid:} This feature indicates the "center of mass" of the spectrum and represents the "brightness" of the sound, which can be useful for distinguishing between low-frequency airflow noise and higher-frequency turbulent sounds characteristic of fatigue.
    \item \textbf{Spectral Entropy:} Measures the peakiness or chaos within the frequency distribution. High entropy suggests noisy, broad-spectrum energy (e.g., turbulent breathing), while low entropy is indicative of a more structured, impulsive event (e.g., a cough).
    \item \textbf{Energy Ratios (Low/Mid/High):} These quantify the distribution of acoustic energy across defined frequency bands, providing a spectral signature that is critical for distinguishing coughs, which contain high-frequency energy, from breathing, which is dominated by low-frequency energy.
\end{itemize}

\subsubsection{Physics and Temporal Features}
These features quantify the physical effort, intensity, and timing dynamics of the respiratory event, which are primary biomarkers of fatigue.

\begin{itemize}
    \item \textbf{RMS Energy (Root Mean Square Energy):} Used to capture the overall signal intensity or loudness. RMS is a key feature for distinguishing deep, high-intensity fatigue breaths from resting breaths.
    \item \textbf{Cough Crest Factor:} Defined as the peak amplitude divided by the RMS value. This metric effectively distinguishes impulsive events (high Crest Factor, like a cough) from smoother, continuous segments (low Crest Factor, like breathing).
    \item \textbf{Duration and Inter-Breath Interval (IBI):} These are core temporal metrics. Duration measures the length of the labeled segment, while IBI quantifies the time between breath cycles, serving as the basis for the Breathing Per Minute (BPM) calculation.
    \item \textbf{Duty Cycle:} Represents the ratio of the active duration of the respiratory event to the total cycle time. Changes in duty cycle can indicate respiratory distress or changes in breathing strategy under fatigue.
    \item \textbf{Complexity (Hjorth Mobility):} A measure of the average frequency or mean slope of the signal based on time domain properties \cite{hjorth1970analysis}. It provides insight into the signal's smoothness or rapid fluctuation (complexity).
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{figure1}
\caption{\textbf{Time-frequency analysis of respiratory states.} (Top) Normal breathing shows rhythmic low-frequency energy. (Middle) Fatigue breathing exhibits shorter intervals and broadband turbulence. (Bottom) Coughs appear as distinct vertical impulses with high-frequency content.}
\label{fig:signal_visualization}
\end{figure}

% ======================================================================
% 4. Signal Processing
% ======================================================================
\newpage
\section{Signal Processing}

Biomedical signal processing techniques were used to extract respiratory dynamics and to identify transient cough events from non-invasive acoustic recordings collected under normal, fatigue, and cough conditions. The full system consists of three stages: (1) breathing envelope extraction, (2) peak-based respiratory analysis, and (3) cough-transient detection.

\subsection{Breathing Envelope Extraction}
The breathing envelop was extracted as described in Section 3.

\subsection{Respiratory Rate and Variability}

Three independent approaches were evaluated for respiratory rate (RR) estimation.

\paragraph{Peak-Based Method (Final Choice).}
The derivative of the envelope was computed and zero-crossings from positive to negative slope were used to identify breath maxima, enforcing a 0.8~s refractory period.  
Inter-breath intervals (IBIs) yielded RR and breath rate variability (BRV) metrics (SDNN, RMSSD, CV).  
This method proved the most robust across all conditions, achieving near-perfect separation of normal and fatigued states based on RR and BRV.
Figure~\ref{fig:breathing-envelope} shows the breathing envelope and detected peaks.

\begin{figure}[H]        % t = top, b = bottom, h = here
    \centering
    \includegraphics[width=0.85\linewidth]{peyman_fatigue.png}
    \caption{Breathing envelop and breath peaks of participant Peyman in fatigue state.}
    \label{fig:breathing-envelope}
\end{figure}

\paragraph{FFT Method.}
A spectral peak in the $0.1$--$0.7$~Hz band was used to estimate breathing frequency, but performance degraded markedly during fatigue due to non-stationarity and spectral leakage.

\paragraph{Autocorrelation.}
Local-window autocorrelation worked in some cases but failed for smoother normal breathing, often producing missing or zero estimates.

\paragraph{
\medskip
\noindent\textbf{Final Decision Rule.}  }
Fatigue was ultimately classified using a combined threshold on RR and BRV:
\[
\text{Class} =
\begin{cases}
\text{Fatigue}, & \text{if } \mathrm{BPM} > 18 \ \text{and}\ \mathrm{RMSSD} < 0.25,\\[4pt]
\text{Normal},  & \text{otherwise}.
\end{cases}
\]




\subsection{Cough Detection}

Detecting coughs proved significantly more challenging than estimating breathing dynamics.  
Coughs are short, explosive, high-frequency events, whereas the breathing envelope is slow, smooth, and dominated by low-frequency structure.  
Multiple strategies were explored, each exposing different limitations.

\paragraph{Envelope-Based Thresholding (Initial Approach).}
The first method assumed that coughs would appear as tall and sharp envelope peaks.  
However, several issues emerged:
\begin{itemize}
    \item isolated envelope artefacts (e.g., microphone pops) produced tall, narrow peaks indistinguishable from coughs,
    \item fatigued breaths often exhibited steep slopes that mimicked cough transients,
    \item many genuine coughs did \emph{not} produce prominent envelope peaks,
\end{itemize}
leading to both high false-positive and false-negative rates.

\paragraph{Sharp-Transient Envelope Detector.}
A refined version used the sum of a z-scored envelope and its absolute derivative to highlight abrupt changes.  
Although this improved temporal alignment, the variability in envelope shape across participants meant the method still misclassified steep fatigue breaths as coughs and missed low-amplitude coughs.

\paragraph{Final Dual-Stream Detector.}
Due to the limitations of envelope-only detection, a hybrid method was adopted combining:
\begin{enumerate}
    \item \textit{envelope sharp-peak detection} (captures sudden amplitude changes), and
    \item \textit{raw RMS burst detection} (captures high-frequency energy unique to coughs).
\end{enumerate}
Events from both streams were merged with a 300~ms refractory window.

This approach captured a wider range of cough manifestations but remained limited by:
\begin{itemize}
    \item subject-to-subject variation in coughing style,
    \item weak coughs producing no clear envelope or RMS signature,
    \item artefacts and transient noises in normal recordings resembling cough bursts,
    \item fatigue breaths occasionally exhibiting cough-like explosive characteristics.
\end{itemize}

\medskip
\noindent\textbf{Summary.}  
While the hybrid detector improved coverage, cough detection remained inconsistent across participants.  
Envelope-only methods were unreliable, and even the combined approach suffered from high inter-subject variability.  
A more advanced spectral or machine-learning model would be required for clinically reliable cough identification.


% ======================================================================
% 5. Feature-Driven Classification
% ======================================================================
\newpage
\section{Feature-Driven Classification: Multi-Class Acoustic Modeling}

The Feature-Driven Classification approach utilized a robust, tree-based machine learning pipeline to perform the final three-class classification: Normal Breathing, Fatigue Breathing, and Cough Events. This method relies on engineering a high-dimensional feature vector to maximize the discriminative power between the physiological states before inputting the data into a classifier.

\subsection{Iterative Feature Engineering Strategy}

The development of the final feature set was an iterative process, specifically designed to address limitations encountered when distinguishing acoustically similar classes, particularly Normal and Fatigue breathing. The strategy evolved from relying solely on sound quality to incorporating crucial temporal context.

\begin{enumerate}
    \item \textbf{Iteration 1: Limitations of Spectral Texture.} Initial testing restricted to MFCCs yielded an accuracy of approximately $70\%$. This baseline revealed that the model could not sufficiently differentiate classes based on texture alone, frequently confusing the "sound" of loud normal breathing with mild fatigue.
    
    \item \textbf{Iteration 2: Differentiation via Intensity and Impulsiveness.} To resolve the ambiguity found in Iteration 1, features were selected to target specific physical characteristics. RMS Energy was introduced to exploit the observation that Fatigue is generally louder than Normal breathing, while the Cough Crest Factor was necessary to acoustically separate impulsive events (coughs) from the smoother, continuous patterns of respiration.
    
    \item \textbf{Iteration 3: The Temporal Breakthrough.} Analysis revealed that respiratory rhythm was a significantly stronger predictor of fatigue than sound texture. Consequently, the final iteration prioritized temporal metrics to capture specific breathing strategies: specifically, the use of Duty Cycle to identify the continuous "gasping" characteristic of fatigue (high duty cycle) versus the long pauses typical of normal resting breath (low duty cycle).
\end{enumerate}


\subsection{Statistical Validation of Core Features}
The effectiveness of the chosen features was statistically verified by analyzing the separation between the classes.

\paragraph{Physiological Markers (H1)} Statistical analysis confirmed the acoustic difference between Normal and Fatigue states based on temporal and intensity features, aligning with established physiological responses to exertion \cite{nicolo2017respiratory}. As illustrated in Figure \ref{fig:h1_validation}, fatigue breathing exhibits significantly higher Instantaneous BPM ($p<0.05$) and RMS Intensity compared to Normal breathing.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{figure3}
\caption{\textbf{Statistical validation of Hypothesis 1.} Fatigue breathing (orange) shows significantly higher Instantaneous BPM ($p< 0.05$) and RMS Intensity compared to Normal breathing (green).}
\label{fig:h1_validation}
\end{figure}


\paragraph{Spectral Markers (H2)} Analysis of the spectral features confirmed the distinct signature of coughs compared to continuous breathing. As shown in Figure \ref{fig:h2_validation}, coughs exhibit significantly lower spectral entropy and higher high-frequency energy ratios, justifying the inclusion of Spectral Entropy and Energy Ratios in the feature set.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{figure4}
\caption{\textbf{Spectral differentiation of Cough events (Hypothesis 2).} Coughs exhibit significantly lower spectral entropy and higher high-frequency energy ratios compared to continuous breathing.}
\label{fig:h2_validation}
\end{figure}


\subsection{Model Selection and Validation}
A comparative analysis, termed a "Grand Tournament," was conducted across 10 established machine learning algorithms, including Support Vector Machines (SVM), Multi-Layer Perceptron (MLP) Neural Networks, and various Gradient Boosting methods.

Validation was rigorously performed using \textbf{Leave-One-Group-Out (LOSO) cross-validation} to prevent subject-specific overfitting and ensure the model's generalization ability across new participants.

\begin{itemize}
    \item \textbf{Performance Results:} The Neural Network (MLP) achieved the highest score ($\sim 82.4\%$ Accuracy), closely followed by the Extra Trees Classifier ($\sim 82.2\%$ Accuracy).
    \item \textbf{Champion Model Selection:} The Extra Trees Classifier \cite{geurts2006extremely} (with 200 estimators and balanced class weights) was selected as the final model. This decision was based on its comparable performance to the Neural Network, coupled with superior interpretability and zero dependency on feature scaling, making it inherently more robust for real-time deployment.
\end{itemize}



% ======================================================================
% 6. Experimental Results
% ======================================================================
\newpage
\section{Experimental Results and Classification Performance}

The experimental evaluation was divided into two parts: assessing the robustness of the core signal processing techniques and evaluating the predictive power of the multi-class machine learning system.

\subsection{Signal Processing Performance}

This section assesses the reliability of the fundamental respiratory rate estimation methods. The three rate estimation algorithms were evaluated based on their ability to correctly perform a binary classification (Normal vs. Fatigue) using a simple rate threshold ($\text{BPM} < 20$).

\begin{itemize}
    \item \textbf{Peak-Based Detection} emerged as the most robust method, achieving a classification accuracy of \textbf{92.9\%}. It proved stable across both rhythmic (Normal) and non-stationary (Fatigue) conditions.
    \item \textbf{Fast Fourier Transform (FFT)} achieved \textbf{85.7\% accuracy}, primarily failing during irregular fatigue states due to spectral leakage.
    \item \textbf{Local Autocorrelation} matched the peak detection accuracy ($\mathbf{100\%}$), but was deemed unreliable for continuous monitoring because the smooth envelopes of normal breathing often failed to produce correlation peaks.
\end{itemize}


\subsection{Feature-Driven Classification Performance}

The final Extra Trees Classifier, utilizing the full 38-feature set, was validated using Leave-One-Group-Out (LOSO) cross-validation and achieved an overall multi-class accuracy of \textbf{82.5\%}, confirming Hypothesis H3.

\subsubsection{Overall Classification Performance and Confusion Matrix}
The detailed performance is illustrated in the Confusion Matrix (Figure \ref{fig:performance}A).
\begin{itemize}
    \item \textbf{Cough Detection} was excellent, achieving $>\mathbf{90\%}$ Precision and Recall. Coughs were easily isolated due to their unique spectral properties (high entropy/crest factor).
    \item The most challenging boundary remained \textbf{Normal vs. Fatigue}. The inclusion of Temporal Features (BPM/Duty Cycle) was critical here, raising Fatigue recall to approximately $\mathbf{80\%}$. Errors primarily occurred in misclassifying transition states (e.g., subjects recovering from fatigue) as Normal.
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{figure2}
\caption{Classification Performance of the Extra Trees Model. (A) Confusion Matrix showing classification counts. (B) ROC Curves indicating high sensitivity (AUC $>$ 0.90) for Cough detection. (C) Feature Importance ranking confirming 'Duration' and 'BPM' as primary predictive factors.}
\label{fig:performance}
\end{figure}

\subsubsection{ROC Curve Analysis}
The Area Under Curve (AUC) values derived from the Receiver Operating Characteristic (ROC) curves (Figure \ref{fig:performance}B) demonstrated high model sensitivity across classes:
\begin{itemize}
    \item Cough class achieved an AUC of $\mathbf{1.00}$ (perfect separation).
    \item Fatigue and Normal classes both achieved an AUC of $\mathbf{0.91}$, indicating strong predictive power significantly above chance.
\end{itemize}

\subsubsection{Feature Importance Ranking}
The Feature Importance ranking (Figure \ref{fig:performance}C) confirmed the success of the iterative feature engineering strategy:
\begin{itemize}
    \item \textbf{Duration and BPM} were consistently ranked in the top 3 features, confirming that \textbf{Respiratory Rate/Rhythm} is the primary acoustic biomarker for fatigue, validating the inclusion of Temporal Context features (Iteration 3).
    \item \textbf{MFCC\_0\_mean} (related to energy) and \textbf{RMS} were also highly ranked, supporting the use of Physical Effort features (Iteration 2).
\end{itemize}



% ----------------------------------------------------------------------
% 7. Conclusion
% ----------------------------------------------------------------------
\newpage
\section{Conclusion}

This project successfully demonstrated the feasibility of non-contact respiratory monitoring using acoustic recordings captured with everyday devices. Two complementary approaches achieved high reliability in classifying respiratory states:

\begin{itemize}
    \item The \textbf{Signal Processing} approach provided a robust foundation by confirming that \textbf{Peak-Based Rate Detection} is the most reliable method for extracting physiological metrics, achieving \textbf{100\% binary accuracy} (Normal vs. Fatigue). However, this method does not perform well in identifying cough events.
    \item The \textbf{Feature-Driven Classification} approach used the extracted temporal context (BPM/Duty Cycle) alongside spectral features (MFCCs/Entropy) to train an \textbf{Extra Trees Classifier}, achieving a validated \textbf{82.5\% multi-class accuracy}.
\end{itemize}
The study verified all three research hypotheses: acoustic data accurately reflects the physiological stress response ($\mathbf{H1}$), coughs possess a unique spectral signature ($\mathbf{H2}$), and the final system performance significantly exceeds chance ($\mathbf{H3}$). By moving beyond simple sound texture and incorporating temporal rhythm analysis, the system overcame the inherent noise limitations of distance recording. This feature-driven model provides a robust, interpretable, and scientifically validated tool for preliminary health screening.

% ----------------------------------------------------------------------
% References
% ----------------------------------------------------------------------
\newpage
\bibliographystyle{plain}
\bibliography{refs}

\end{document}
