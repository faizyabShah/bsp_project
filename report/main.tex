\documentclass[12pt, a4paper]{article}

% --- Packages ---
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{url}
\usepackage{array}
\usepackage{float}
\usepackage{enumitem}
\usepackage[margin=1in]{geometry}

% Hyperref (Must be loaded last)
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}

\begin{document}

% ----------------------------------------------------------------------
% Title Page
% ----------------------------------------------------------------------
\begin{titlepage}
    \centering
    \vspace*{\fill}

    {\huge \textbf{Acoustic Breathing and Cough Detection for Fatigue Monitoring Using a Laptop Microphone} \par}

    \vspace{2cm}

    {\Large \textbf{Group OLEMFA} \par}
    \vspace{0.5em}
    {\large
    Olena Mikhailova (H7OGWN) \\
    Muhammed Emre Candir (YDY84J) \\
    Faizyab Ali Shah (GUBG3I) \\
    }

    \vspace{1.5em}
    {\small \emph{Course: Biomedical Signal Processing} \par}

    \vspace{2cm}
    {\small \today}

    \vspace*{\fill}
\end{titlepage}

% ----------------------------------------------------------------------
% Abstract
% ----------------------------------------------------------------------
\newpage
\begin{abstract}
\noindent
This project investigates whether non-contact acoustic measurements, recorded using a standard smartphone or laptop microphone, can be used to monitor fatigue-related changes in breathing. We developed a complete signal-processing pipeline that includes envelope extraction, breathing rate estimation, and cough detection. Two distinct machine learning approaches were developed and analyzed: a Feature-Driven Classification system and a foundational Signal Processing system. The Feature-Driven system used a 38-feature vector (combining temporal rhythm, spectral texture, and physical effort features) with an Extra Trees Classifier, achieving an overall multi-class accuracy of 82.5\%. The system proved that Temporal rhythm (BPM/Duty Cycle) is the primary biomarker for acoustic fatigue monitoring. Complementarily, the foundational Signal Processing system successfully implemented a Peak-Based Rate Detection method, achieving 92.9\% accuracy in the binary classification of Normal vs. Fatigue states using a simple BPM threshold. The results demonstrate that acoustic data, even from consumer-grade hardware, accurately reflects underlying physiological stress responses.
\end{abstract}

\newpage
\tableofcontents


% ----------------------------------------------------------------------
% 1. Introduction
% ----------------------------------------------------------------------
\newpage
\section{Introduction}

\subsection{Project Overview and Objectives}
Fatigue monitoring is a critical component in various safety-sensitive fields, but traditional approaches often rely on invasive sensors or subjective self-reporting. This project proposes a non-contact, acoustics-based solution \cite{larson2011spirosmart}. The objective is to develop a three-class acoustic classification system capable of distinguishing between physiological states using only a standard laptop or smartphone microphone. Specifically, the system aims to automatically detect and classify raw audio data into:

\begin{itemize}
    \item Normal Breathing (resting state),
    \item Fatigue Breathing (post-exercise state),
    \item Cough Events.
\end{itemize}

The primary goal is to implement a robust Python-based pipeline for multi-class detection of these respiratory audio events. As a secondary objective, we aim to statistically quantify the acoustic and temporal differences between states. This involves analyzing variations in breathing rate, amplitude, and spectral content to identify reliable biomarkers of fatigue. Furthermore, we ensure that the entire workflow—from acquisition to feature extraction—is reproducible and open-source.

\subsection{Research Hypotheses}
To guide the signal processing strategy and feature selection, we formulate three hypotheses regarding the acoustic characteristics of respiratory sounds:

\begin{description}
    \item[H1 (Fatigue Markers):] Fatigue breathing will exhibit statistically significant increases in breathing rate, amplitude, and temporal irregularity compared to normal resting breathing.
    \item[H2 (Cough Differentiation):] Cough sounds possess distinct short-time energy profiles and spectral entropy characteristics, allowing them to be reliably segmented from background breathing noise \cite{swarna2020cough}.
    \item[H3 (Classification Feasibility):] A combination of temporal envelope features and spectral ratios will provide sufficient discriminative power for accurate multi-class classification using non-contact audio.
\end{description}

% ----------------------------------------------------------------------
% 2. Data Collection and Dataset Description
% ----------------------------------------------------------------------
\newpage
\section{Data Collection and Dataset Description}

To support analysis, we collected a controlled dataset consisting of 24 recordings from 8 participants (Emre, Olena, Narmeen, Sneha, Paula, Yernur, Peyman, Sofia). Each participant contributed three recordings corresponding to the target classes: normal breathing, fatigued breathing, and coughing.

Recordings were acquired using standard microphones in quiet indoor environments. The device was positioned approximately 5--10 cm from the participant’s mouth to maintain consistent recording quality while remaining fully non-contact.

Each participant followed a defined protocol:
\begin{enumerate}
    \item \textbf{Normal Breathing:} A 60-second recording captured at rest, producing slow and smooth respiratory cycles.
    \item \textbf{Fatigue Breathing:} Participants performed 2 minutes of physical exercise (stair climbing or squats) and immediately recorded 60 seconds of post-exertion breathing.
    \item \textbf{Cough Recording:} Participants recorded 60 seconds during which they produced deliberate coughs approximately every 5 seconds.
\end{enumerate}

All audio files were manually reviewed to ensure correct labeling. Each recording was stored along with metadata such as the start time, end time, and label for supervised training.

% ======================================================================
% 3. Preprocessing and Envelope Extraction
% ======================================================================
\newpage
\section{Audio Preprocessing and Envelope Extraction}

To transition from raw audio to interpretable respiratory biomarkers, a unified preprocessing pipeline was implemented. This stage aims to mitigate environmental noise, standardize amplitude levels across heterogeneous recording devices, and isolate the low-frequency respiratory component. All audio data was ingested at the native sampling rate using \texttt{librosa} \cite{mcfee2015librosa} before entering the multi-stage processing block.

\subsection{General Preprocessing Pipeline}
Raw audio files were initially sliced strictly according to manual start/end timestamps. Early trials attempting to filter short segments ($< 0.1$ s) resulted in significant data loss (dropping valid short coughs). Therefore, the final pipeline adopted a "No-Filter" approach, preserving all 422 segments to ensure the integrity of transient events like coughs.

\subsection{Respiratory Envelope Extraction}
The core of the analysis relies on the generation of a smooth, time-domain breathing envelope. We define the envelope extraction process as a sequential pipeline designed to demodulate the amplitude of the breathing sounds.

The envelope $E(t)$ is derived from the raw signal $x(t)$ via the Hilbert Transform:
\begin{equation}
    E(t) = |x(t) + i\mathcal{H}(x(t))|
\end{equation}
where $\mathcal{H}(\cdot)$ denotes the Hilbert operator implemented via \texttt{SciPy} \cite{virtanen2020scipy}. The following steps were applied primarily to support the extraction of Temporal Features (e.g., BPM, IBI):

\begin{description}
    \item[1. Normalization:] Signals were normalized to eliminate subject-dependent loudness differences and microphone gain variations.
    
    \item[2. Savitzky–Golay Smoothing:] To attenuate high-frequency noise while preserving the shape of respiratory peaks, we applied a Savitzky–Golay filter.
    
    \item[3. Low-Pass Filtering:] A cut-off frequency of \textbf{0.7 Hz} was selected. This effectively isolates the respiratory band (corresponding to $\approx$ 42 breaths per minute) and removes heart sounds and muscle artifacts \cite{charlton2018breathing}.
    
    \item[4. Z-Score Normalization:] The signal was normalized to zero mean and unit variance to allow for adaptive thresholding across participants.
    
    \item[5. Downsampling:] The final envelope was downsampled to \textbf{100 Hz} to create a lightweight signal suitable for analysis.
\end{description}

\subsection{Frame-Based Feature Engineering}

To successfully classify the three physiological states (Normal, Fatigue, and Cough), it was necessary to extract a rich, high-dimensional feature set that captures both the subtle texture of continuous breathing and the impulsive nature of cough events. These features were computed using a short-time framing approach applied to the segmented audio before aggressive low-pass filtering, preserving the high-frequency content critical for spectral analysis. The final feature vector aggregated 38 metrics, categorized as follows:

\subsubsection{Spectral and Texture Features}
These features analyze the frequency domain to describe the characteristic "sound" or timbre of the respiratory signal.

\begin{itemize}
    \item \textbf{Mel-Frequency Cepstral Coefficients (MFCCs):} A set of $13$ coefficients and their corresponding standard deviations were extracted to form a $26$-dimensional vector. MFCCs compactly represent the spectral envelope of the respiratory sound, effectively capturing the sound's timbre.
    \item \textbf{Spectral Centroid:} This feature indicates the "center of mass" of the spectrum and represents the "brightness" of the sound, which can be useful for distinguishing between low-frequency airflow noise and higher-frequency turbulent sounds characteristic of fatigue.
    \item \textbf{Spectral Entropy:} Measures the peakiness or chaos within the frequency distribution. High entropy suggests noisy, broad-spectrum energy (e.g., turbulent breathing), while low entropy is indicative of a more structured, impulsive event (e.g., a cough).
    \item \textbf{Energy Ratios (Low/Mid/High):} These quantify the distribution of acoustic energy across defined frequency bands, providing a spectral signature that is critical for distinguishing coughs, which contain high-frequency energy, from breathing, which is dominated by low-frequency energy.
\end{itemize}

\subsubsection{Physics and Temporal Features}
These features quantify the physical effort, intensity, and timing dynamics of the respiratory event, which are primary biomarkers of fatigue.

\begin{itemize}
    \item \textbf{RMS Energy (Root Mean Square Energy):} Used to capture the overall signal intensity or loudness. RMS is a key feature for distinguishing deep, high-intensity fatigue breaths from resting breaths.
    \item \textbf{Cough Crest Factor:} Defined as the peak amplitude divided by the RMS value. This metric effectively distinguishes impulsive events (high Crest Factor, like a cough) from smoother, continuous segments (low Crest Factor, like breathing).
    \item \textbf{Duration and Inter-Breath Interval (IBI):} These are core temporal metrics. Duration measures the length of the labeled segment, while IBI quantifies the time between breath cycles, serving as the basis for the Breathing Per Minute (BPM) calculation.
    \item \textbf{Complexity (Hjorth Mobility):} A measure of the average frequency or mean slope of the signal. It provides insight into the signal's smoothness or rapid fluctuation (complexity).
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{figure1}
\caption{\textbf{Time-frequency analysis of respiratory states.} (Top) Normal breathing shows rhythmic low-frequency energy. (Middle) Fatigue breathing exhibits shorter intervals and broadband turbulence. (Bottom) Coughs appear as distinct vertical impulses with high-frequency content.}
\label{fig:signal_visualization}
\end{figure}

% ======================================================================
% 4. Signal Processing
% ======================================================================
\newpage
\section{Signal Processing}

To quantify respiratory dynamics and detect transient cough events, we implemented a dual-stream analysis framework based purely on signal processing techniques.

\subsection{Comparative Respiratory Rate Estimation}

Accurate estimation of the respiratory rate (RR) is critical for extracting Breath Rate Variability (BRV) metrics. We evaluated three signal processing techniques to determine the most robust method for analyzing non-stationary fatigue data \cite{charlton2018breathing}.

\subsubsection{Method 1: Peak-Based Detection (Primary Strategy)}
The peak detection algorithm operates on the time-domain derivative of the breathing envelope. A breath cycle is defined by the zero-crossing points where the slope transitions from positive to negative.
\begin{enumerate}
    \item \textbf{Differentiation:} Calculate the first derivative $\frac{dE}{dt}$ of the smoothed envelope.
    \item \textbf{Peak Identification:} Identify local maxima (zero-crossings) and enforce a minimum breath separation of \textbf{0.8 seconds} to prevent false positives from micro-fluctuations.
    \item \textbf{Metric Extraction:} Inter-breath intervals (IBI) are derived to compute SDNN and RMSSD metrics.
\end{enumerate}
\textbf{Performance:} This method was the most physiologically aligned, achieving \textbf{92.9\% accuracy}. It proved robust to the irregularity of fatigued breathing and served as the basis for the final classification.

\subsubsection{Method 2: Fast Fourier Transform (FFT)}
The spectral approach estimates the dominant breathing frequency by locating the maximum magnitude in the power spectrum within the physiological band ($0.1 \le f \le 0.7$ Hz).
\begin{itemize}
    \item \textit{Limitation:} While effective for rhythmic, normal breathing, the FFT assumes signal stationarity. In fatigued states, breathing patterns become irregular (shallow breaths, pauses), causing spectral leakage which reduced accuracy to \textbf{85.7\%}.
\end{itemize}

\subsubsection{Method 3: Local Autocorrelation}
This method estimates periodicity by correlating the signal with delayed versions of itself within 10-second sliding windows (2-second hop).
\begin{itemize}
    \item \textit{Limitation:} Although it achieved high accuracy in specific fatigue cases, it proved unreliable for steady-state normal breathing. The smooth, low-contrast envelopes of normal breathing often failed to produce strong correlation peaks, yielding 0 BPM results.
\end{itemize}

\subsection{Spectral-Transient Cough Detection}
Coughs are spectrally and temporally different from breathing, characterized by high-frequency bursts (600--3000 Hz) and steep rise times. We designed a dual-band transient detector to robustly identify these events.

The algorithm monitors energy distribution across two specific frequency bands:
\begin{itemize}
    \item \textbf{Low-Frequency (LF):} Breathing energy band ($< 300$ Hz).
    \item \textbf{High-Frequency (HF):} Cough signature band ($600 - 3000$ Hz).
\end{itemize}

A frame $n$ is classified as a cough if it satisfies the dual-threshold condition:
\begin{equation}
    E_{HF}(n) > \theta_{energy} \quad \text{AND} \quad \frac{E_{HF}(n)}{E_{LF}(n)} > \theta_{ratio}
\end{equation}

where $\theta$ represents adaptive thresholds. To prevent double-counting of single events, a refractory period of \textbf{250 ms} is enforced between consecutive detections. This ratio-based approach significantly reduced false positives compared to standard energy-only detectors \cite{swarna2020cough}.

\subsection{Final Classification Logic}
The final system aggregates the outputs of these components into a unified decision rule for identifying fatigue. Based on the experimental results, the Peak-Based method provided the most reliable separation. The classification logic is defined as:
\begin{equation}
    \text{Class} = 
    \begin{cases} 
    \text{Normal} & \text{if } \text{BPM}_{peak} < 20 \\
    \text{Fatigue} & \text{otherwise}
    \end{cases}
\end{equation}
This threshold was derived from the observation that fatigued participants exhibited significantly higher respiratory rates and irregularity compared to the resting baseline.


% ======================================================================
% 5. Feature-Driven Classification
% ======================================================================
\newpage
\section{Feature-Driven Classification: Multi-Class Acoustic Modeling}

The Feature-Driven Classification approach utilized a robust, tree-based machine learning pipeline to perform the final three-class classification: Normal Breathing, Fatigue Breathing, and Cough Events. This method relies on engineering a high-dimensional feature vector to maximize the discriminative power between the physiological states before inputting the data into a classifier.

\subsection{Iterative Feature Engineering Strategy}

The development of the final feature set was an iterative process, specifically designed to address limitations encountered when distinguishing acoustically similar classes, particularly Normal and Fatigue breathing. The strategy evolved from relying solely on sound quality to incorporating crucial temporal context.

\begin{enumerate}
    \item \textbf{Iteration 1: Spectral Texture (MFCCs)}: Initial testing focused on spectral characteristics using only Mel-Frequency Cepstral Coefficients (MFCCs). This yielded an accuracy of approximately $70\%$, as the model struggled to differentiate the "sound" of loud normal breathing from mild fatigue based on texture alone.
    \item \textbf{Iteration 2: Physical Effort and Impulsiveness}: To capture the physical intensity of the breath and the transient nature of coughs, features representing energy and shape were introduced.
    \begin{itemize}
        \item \textbf{RMS Energy} was included to quantify overall loudness (intensity), where Fatigue is generally louder than Normal breathing.
        \item \textbf{Cough Crest Factor} (peak-to-RMS ratio) was added to distinguish impulsive events, like coughs, from the smoother, continuous pattern of breathing.
    \end{itemize}
    \item \textbf{Iteration 3: Temporal Context (The Breakthrough)}: Analysis revealed that rhythm (rate and pattern) was a significantly stronger predictor of fatigue than sound texture. A context-aware extractor was implemented to calculate temporal features derived from the envelope analysis described in Section 4.1:
    \begin{itemize}
        \item \textbf{BPM (Instantaneous)}: Derived from the Inter-Breath Interval (IBI).
        \item \textbf{Duty Cycle}: The ratio of breath duration to the total breath cycle. This metric is crucial because fatigue is characterized by a high duty cycle (continuous gasping), while normal breathing exhibits a low duty cycle (long pauses).
    \end{itemize}
\end{enumerate}

\subsubsection{Statistical Validation of Core Features}
The effectiveness of the chosen features was statistically verified by analyzing the separation between the classes.

\paragraph{Physiological Markers (H1)} Statistical analysis confirmed the acoustic difference between Normal and Fatigue states based on temporal and intensity features, supporting the feature engineering choices in Iterations 2 and 3. As illustrated in Figure \ref{fig:h1_validation}, Fatigue breathing exhibits significantly higher Instantaneous BPM ($p<0.05$) and RMS Intensity compared to Normal breathing.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{figure3}
\caption{\textbf{Statistical validation of Hypothesis 1.} Fatigue breathing (orange) shows significantly higher Instantaneous BPM ($p< 0.05$) and RMS Intensity compared to Normal breathing (green).}
\label{fig:h1_validation}
\end{figure}


\paragraph{Spectral Markers (H2)} Analysis of the spectral features confirmed the distinct signature of coughs compared to continuous breathing. As shown in Figure \ref{fig:h2_validation}, coughs exhibit significantly lower spectral entropy and higher high-frequency energy ratios, justifying the inclusion of Spectral Entropy and Energy Ratios in the feature set.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\linewidth]{figure4}
\caption{\textbf{Spectral differentiation of Cough events (Hypothesis 2).} Coughs exhibit significantly lower spectral entropy and higher high-frequency energy ratios compared to continuous breathing.}
\label{fig:h2_validation}
\end{figure}


\subsection{Final Feature Set and Model Selection}

\subsubsection{Final Feature Vector}
The final system utilized a comprehensive 38-feature set to provide maximum discriminative power, encompassing the following four categories:

\begin{itemize}
    \item \textbf{Temporal Features:} BPM, Duty Cycle, and IBI.
    \item \textbf{Physics Features:} Duration, RMS Energy, and Crest Factor.
    \item \textbf{Spectral Features:} Energy Ratios (Low/Mid/High) and Spectral Entropy.
    \item \textbf{Texture/Complexity Features:} 13 MFCC means, 13 MFCC standard deviations, and Hjorth Mobility.
\end{itemize}

\subsubsection{Model Selection and Validation}
A comparative analysis, termed a "Grand Tournament," was conducted across 10 established machine learning algorithms, including Support Vector Machines (SVM), Multi-Layer Perceptron (MLP) Neural Networks, and various Gradient Boosting methods.

Validation was rigorously performed using \textbf{Leave-One-Group-Out (LOSO) cross-validation} to prevent subject-specific overfitting and ensure the model's generalization ability across new participants.

\begin{itemize}
    \item \textbf{Performance Results:} The Neural Network (MLP) achieved the highest score ($\sim 82.4\%$ Accuracy), closely followed by the Extra Trees Classifier ($\sim 82.2\%$ Accuracy).
    \item \textbf{Champion Model Selection:} The Extra Trees Classifier (with 200 estimators and balanced class weights) was selected as the final model. This decision was based on its comparable performance to the Neural Network, coupled with superior interpretability and zero dependency on feature scaling, making it inherently more robust for real-time deployment.
\end{itemize}

\subsubsection{Feature Set Necessity}
An analysis using Recursive Feature Elimination (RFE) was conducted to explore feature reduction; however, this resulted in a significant drop in accuracy ($\sim 73\%$). This demonstrated that even the features initially considered "weak," such as the lower-order MFCCs, contained subtle, non-linear signals necessary for achieving the optimal decision boundary, justifying the retention of the full 38-feature set.

% ======================================================================
% 6. Experimental Results
% ======================================================================
\newpage
\section{Experimental Results and Classification Performance}

The experimental evaluation was divided into two parts: assessing the robustness of the core signal processing techniques and evaluating the predictive power of the multi-class machine learning system.

\subsection{Signal Processing Performance and Physiological Validation}

This approach focused on validating the research hypotheses (H1, H2) through statistical analysis and assessing the reliability of the fundamental respiratory rate estimation methods.

\subsubsection{Respiratory Rate Estimation Accuracy}
The three rate estimation algorithms were evaluated based on their ability to correctly perform a binary classification (Normal vs. Fatigue) using a simple rate threshold ($\text{BPM} < 20$).

\begin{itemize}
    \item \textbf{Peak-Based Detection} emerged as the most robust method, achieving a classification accuracy of \textbf{92.9\%}. It proved stable across both rhythmic (Normal) and non-stationary (Fatigue) conditions.
    \item \textbf{Fast Fourier Transform (FFT)} achieved \textbf{85.7\% accuracy}, primarily failing during irregular fatigue states due to spectral leakage.
    \item \textbf{Local Autocorrelation} matched the peak detection accuracy ($\mathbf{92.9\%}$), but was deemed unreliable for continuous monitoring because the smooth envelopes of normal breathing often failed to produce correlation peaks.
\end{itemize}

\subsubsection{Scientific Hypothesis Verification}
Statistical validation using T-Tests confirmed the physiological basis of the feature engineering strategy:
\begin{itemize}
    \item \textbf{H1 (Fatigue Markers)}: Confirmed. T-tests for both Breathing Rate (BPM) and Intensity (RMS) yielded $\mathbf{p < 0.05}$ (Significant). Fatigue samples showed a statistically higher mean BPM and RMS intensity compared to Normal breathing . This confirmed that the acoustic data accurately reflects the underlying physiological stress response.
    \item \textbf{H2 (Cough Differentiation)}: Confirmed. T-tests for Spectral Entropy yielded $\mathbf{p < 0.001}$ (Highly Significant). Coughs exhibited much lower entropy (structured impulse) and contained significantly more energy $>2000$ Hz, confirming they possess a unique spectral signature distinct from continuous breathing .
\end{itemize}

\subsection{Feature-Driven Classification Performance}

The final Extra Trees Classifier, utilizing the full 38-feature set, was validated using Leave-One-Group-Out (LOSO) cross-validation and achieved an overall multi-class accuracy of \textbf{82.5\%}, confirming Hypothesis H3.

\subsubsection{Overall Classification Performance and Confusion Matrix}
The detailed performance is illustrated in the Confusion Matrix (Figure \ref{fig:performance}A).
\begin{itemize}
    \item \textbf{Cough Detection} was excellent, achieving $>\mathbf{90\%}$ Precision and Recall. Coughs were easily isolated due to their unique spectral properties (high entropy/crest factor).
    \item The most challenging boundary remained \textbf{Normal vs. Fatigue}. The inclusion of Temporal Features (BPM/Duty Cycle) was critical here, raising Fatigue recall to approximately $\mathbf{80\%}$. Errors primarily occurred in misclassifying transition states (e.g., subjects recovering from fatigue) as Normal.
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{figure2}
\caption{Classification Performance of the Extra Trees Model. (A) Confusion Matrix showing classification counts. (B) ROC Curves indicating high sensitivity (AUC $>$ 0.90) for Cough detection. (C) Feature Importance ranking confirming 'Duration' and 'BPM' as primary predictive factors.}
\label{fig:performance}
\end{figure}

\subsubsection{ROC Curve Analysis}
The Area Under Curve (AUC) values derived from the Receiver Operating Characteristic (ROC) curves (Figure \ref{fig:performance}B) demonstrated high model sensitivity across classes:
\begin{itemize}
    \item Cough class achieved an AUC of $\mathbf{1.00}$ (perfect separation).
    \item Fatigue and Normal classes both achieved an AUC of $\mathbf{0.91}$, indicating strong predictive power significantly above chance.
\end{itemize}

\subsubsection{Feature Importance Ranking}
The Feature Importance ranking (Figure \ref{fig:performance}C) confirmed the success of the iterative feature engineering strategy:
\begin{itemize}
    \item \textbf{Duration and BPM} were consistently ranked in the top 3 features, confirming that \textbf{Respiratory Rate/Rhythm} is the primary acoustic biomarker for fatigue, validating the inclusion of Temporal Context features (Iteration 3).
    \item \textbf{MFCC\_0\_mean} (related to energy) and \textbf{RMS} were also highly ranked, supporting the use of Physical Effort features (Iteration 2).
\end{itemize}

\vspace{1em}
\noindent The system performance of $\mathbf{82.5\%}$ accuracy, verified via robust LOSO validation, successfully confirmed Hypothesis 3.

% ----------------------------------------------------------------------
% 7. Conclusion
% ----------------------------------------------------------------------
\newpage
\section{Conclusion}

This project successfully demonstrated the feasibility of non-contact respiratory monitoring using acoustic recordings captured with everyday devices. Two complementary approaches achieved high reliability in classifying respiratory states:

\begin{itemize}
    \item The \textbf{Signal Processing} approach provided a robust foundation by confirming that \textbf{Peak-Based Rate Detection} is the most reliable method for extracting physiological metrics, achieving \textbf{92.9\% binary accuracy} (Normal vs. Fatigue).
    \item The \textbf{Feature-Driven Classification} approach used the extracted temporal context (BPM/Duty Cycle) alongside spectral features (MFCCs/Entropy) to train an \textbf{Extra Trees Classifier}, achieving a validated \textbf{82.5\% multi-class accuracy}.
\end{itemize}
The study verified all three research hypotheses: acoustic data accurately reflects the physiological stress response ($\mathbf{H1}$), coughs possess a unique spectral signature ($\mathbf{H2}$), and the final system performance significantly exceeds chance ($\mathbf{H3}$). By moving beyond simple sound texture and incorporating temporal rhythm analysis, the system overcame the inherent noise limitations of distance recording. This feature-driven model provides a robust, interpretable, and scientifically validated tool for preliminary health screening.

% ----------------------------------------------------------------------
% References
% ----------------------------------------------------------------------
\newpage
\bibliographystyle{plain}
\bibliography{refs}

\end{document}
